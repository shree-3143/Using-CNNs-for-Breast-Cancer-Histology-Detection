{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shree-3143/Using-CNNs-for-Breast-Cancer-Histology-Detection/blob/main/FINAL_Breast_Cancer_Histology_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONsdiDxs-c4E"
      },
      "source": [
        "### Read Me\n",
        "To run the program, download the BreakHis histology dataset from Kaggle, convert to a Zip file, and place into your Google Drive. Provide the path from Google Drive in \"zip_path\", and click \"Run All\" for the program to commence. The last cell (at the very end) does a prediction on a random image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqapjAeH5ZpQ"
      },
      "outputs": [],
      "source": [
        "# Import all required libraries --> for model building, training, evaluation, and image handling\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.models import resnet18\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnCg84k-5yh2",
        "outputId": "9eb88559-db3b-489d-89ef-7e976423910c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Set-up device-agnostic code\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "EKC71mUj69pi",
        "outputId": "615c413b-8908-4e78-e81c-d8d04776b762"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3442609279.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Mounting Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mzip_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/BreaKHis_v1.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "# Loading and unzipping the BreakHis dataset from Google Drive\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "# Mounting Google Drive\n",
        "drive.mount(\"/content/drive\")\n",
        "zip_path = \"/content/drive/MyDrive/BreaKHis_v1.zip\"\n",
        "\n",
        "# Create data folder\n",
        "data_path = Path(\"/data\")\n",
        "data_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Unzip the uploaded BreakHis.zip\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "  print(\"Unzipping BreakHis data\")\n",
        "  zip_ref.extractall(data_path)\n",
        "\n",
        "# Check extracted contents\n",
        "breakhis_path = data_path\n",
        "if breakhis_path.exists():\n",
        "  print(\"extracted\")\n",
        "else:\n",
        "  print(\"check folder structure\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf7DTp0U8ChP"
      },
      "outputs": [],
      "source": [
        "import os # allows the code to interact with the operating system\n",
        "# Walks through the target directory, returning its contents\n",
        "# Returns a print of: no. of subdirectories, no. of images(files) in each subdirectory, name of each subdirectory\n",
        "def walk_through_dir(dir_path):\n",
        "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "      print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxWK2_mh8WVB"
      },
      "outputs": [],
      "source": [
        "# Calling the walk_through_dir to display the structure of the BreakHis dataset\n",
        "walk_through_dir(breakhis_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgEy8fOr8mmg"
      },
      "outputs": [],
      "source": [
        "import os # used to interact with the operating system\n",
        "import shutil # useful for copying/moving entire files or filders\n",
        "import random # used to generate random numbers or make random choices\n",
        "from pathlib import Path # object-oriented way to handle filesystem paths\n",
        "\n",
        "# Original dataset path\n",
        "original_path = Path(\"/data/BreaKHis_v1/BreaKHis_v1/histology_slides/breast\")\n",
        "\n",
        "# In this project, we are only dealing with two subtypes, and only images of magnification 40x\n",
        "benign_subtype = \"fibroadenoma\"\n",
        "malignant_subtype = \"ductal_carcinoma\"\n",
        "magnification = \"40X\"\n",
        "\n",
        "# SPLITTING THE DATASET INTO TRAINING AND TESTING DATASETS\n",
        "\n",
        "# Paths for the new split dataset\n",
        "base_split_path = Path(\"/data/BreaKHis_split\")\n",
        "train_path = base_split_path / \"train\"\n",
        "test_path = base_split_path / \"test\"\n",
        "\n",
        "if base_split_path.exists():\n",
        "  shutil.rmtree(base_split_path)\n",
        "\n",
        "# Creating train/test directories, and their benign/malignant subfolders\n",
        "# Looping over both paths so that we can create subfolders in each\n",
        "for split in [train_path, test_path]: # list of two path objects - one for where the training data will go, and one for test data:\n",
        "  (split / \"benign\").mkdir(parents=True, exist_ok=True) # Creating any missing parent folders, and don't throw an error if the folder already exists\n",
        "  (split / \"malignant\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Function to copy images into train/test directories with an 80-20 split\n",
        "def copy_images(label, subtype):\n",
        "  source_subtype_path = original_path / label / \"SOB\" / subtype # Navigating to the correct subtype folder\n",
        "  if not source_subtype_path.exists():\n",
        "    print(f\"Warning: {source_subtype_path} does not exist.\") # Print a warning and exist the folder if the source subtype folder doesn't exist\n",
        "    return\n",
        "\n",
        "  patient_folders = [p for p in source_subtype_path.iterdir() if p.is_dir()] # only include directories/folders\n",
        "\n",
        "  all_images = [] # empty list to store image file paths\n",
        "  for patient_folder in patient_folders: # loop through each patient folder from earlier\n",
        "    img_folder = patient_folder / magnification # look for a folder named after the magnification level\n",
        "    # print a warning and skip to the next folder if the folder doesn't exist\n",
        "    if not img_folder.exists():\n",
        "      print(f\"Missing magnification folder: {img_folder}\")\n",
        "      continue\n",
        "    # find all image files matching these extensions\n",
        "    images = list(img_folder.glob(\"*.png\")) + list(img_folder.glob(\"*.jpg\")) + list(img_folder.glob(\"*.jpeg\"))\n",
        "    all_images.extend(images) # add all found images to the list\n",
        "\n",
        "  print(f\"Found {len(all_images)} images for {label} - {subtype} at {magnification}\")\n",
        "\n",
        "  # Splitting into training and testing datasets using the ratio\n",
        "  random.shuffle(all_images)\n",
        "  split_idx = int(len(all_images) * 0.8)\n",
        "  train_imgs = all_images[:split_idx] # all images up till the splitting index\n",
        "  test_imgs = all_images[split_idx:] # all images after the splitting index\n",
        "\n",
        "  # loop over every image path in the set of training images\n",
        "  for img_path in train_imgs:\n",
        "    # build the destination path under the correct label\n",
        "    dest = train_path / label / img_path.name\n",
        "    shutil.copy(img_path, dest) # copy the image file from og location to destination folder\n",
        "\n",
        "  # repeat for set of testing images\n",
        "  for img_path in test_imgs:\n",
        "    dest = test_path / label / img_path.name\n",
        "    shutil.copy(img_path, dest)\n",
        "\n",
        "  print(f\"Copied {len(train_imgs)} images to train/{label}\")\n",
        "  print(f\"Copied {len(test_imgs)} images to train/{label}\")\n",
        "\n",
        "# Run for benign and malignant subtypes\n",
        "copy_images(\"benign\", benign_subtype)\n",
        "copy_images(\"malignant\", malignant_subtype)\n",
        "\n",
        "# Check folders\n",
        "for split in [train_path, test_path]:\n",
        "  print(f\"\\nContents of {split}:\")\n",
        "  for label in [\"benign\", \"malignant\"]:\n",
        "    folder = split / label\n",
        "    # print out number of images found in benign and malignant folders\n",
        "    print(f\"- {label}: {len(list(folder.glob('*')))} images\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yj5aCero_clp"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "breakhis_path = Path(\"/data/BreaKHis_split\")\n",
        "\n",
        "# Creating two new path objects --> each pointing to the training/testing folder inside the dataset folder\n",
        "train_dir = breakhis_path / \"train\"\n",
        "test_dir = breakhis_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPSfG8onF4DA"
      },
      "outputs": [],
      "source": [
        "# Recursively list all files in the training directory\n",
        "all_files = list(train_dir.rglob(\"*\"))\n",
        "print(f\"Total files found in train_dir recursively: {len(all_files)}\")\n",
        "\n",
        "print(\"Some sample files:\")\n",
        "for f in all_files[:10]:\n",
        "    print(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cKdqQx6GJ3g"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_extensions = [\".jpg\", \"jpeg\", \".png\"]\n",
        "\n",
        "# Get all image files directly under benign and malignant folders\n",
        "train_images = [] # creates an empty list to contain images from the training directory\n",
        "for class_folder in train_dir.iterdir(): # iterates through each item in the train_dir folder\n",
        "  if class_folder.is_dir(): # checkes that it is a directory\n",
        "    for img_file in class_folder.iterdir(): # iterates through each image in the directory\n",
        "      if img_file.suffix.lower() in image_extensions: # filters for image files based on the extensions\n",
        "        train_images.append(img_file) # if it is an image, add the file to the list\n",
        "print(f\"Found {len(train_images)} images in train directory\") # print the number of images in the directory\n",
        "\n",
        "if train_images:\n",
        "  random_img = random.choice(train_images) # select a random image\n",
        "  print(f\"Random image selected: {random_img}\")\n",
        "  print(f\"Image class: {random_img.parent.name}\") # print the class of the random image (Benign/Malignant)\n",
        "\n",
        "  img = Image.open(random_img)\n",
        "  img.show # show the image\n",
        "\n",
        "  # Turn the image into an array\n",
        "  img_as_array = np.asarray(img)\n",
        "\n",
        "  # Plot the image with matplotlib\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  plt.imshow(img_as_array)\n",
        "  plt.title(f\"Image class: {random_img.parent.name} | Image shape: {img_as_array.shape}\")\n",
        "  plt.axis(False);\n",
        "else:\n",
        "  print(\"No images found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwG0B6a7rFZp"
      },
      "outputs": [],
      "source": [
        "# Repeat the same steps for the testing dataset\n",
        "import random\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_extensions = [\".jpg\", \"jpeg\", \".png\"]\n",
        "\n",
        "# Get all image files directly under benign and malignant folders\n",
        "test_images = []\n",
        "for class_folder in test_dir.iterdir():\n",
        "  if class_folder.is_dir():\n",
        "    for img_file in class_folder.iterdir():\n",
        "      if img_file.suffix.lower() in image_extensions:\n",
        "        test_images.append(img_file)\n",
        "print(f\"Found {len(test_images)} images in test directory\")\n",
        "\n",
        "if test_images:\n",
        "  random_img = random.choice(test_images)\n",
        "  print(f\"Random image selected: {random_img}\")\n",
        "  print(f\"Image class: {random_img.parent.name}\")\n",
        "\n",
        "  img = Image.open(random_img)\n",
        "  img.show\n",
        "\n",
        "  # Turn the image into an array\n",
        "  img_as_array = np.asarray(img)\n",
        "\n",
        "  # Plot the image with matplotlib\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  plt.imshow(img_as_array)\n",
        "  plt.title(f\"Image class: {random_img.parent.name} | Image shape: {img_as_array.shape}\")\n",
        "  plt.axis(False);\n",
        "else:\n",
        "  print(\"No images found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Etk4P0qjsRmO"
      },
      "outputs": [],
      "source": [
        "# Importing libraries for image transformations\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r315lCGjsTSF"
      },
      "outputs": [],
      "source": [
        "# Write transform for image\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize the images to 224x224\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    # Flip the images randomly on the horizontal\n",
        "    transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
        "    # Turn the image into a torch.Tensor\n",
        "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK9uzaWYsdpG"
      },
      "outputs": [],
      "source": [
        "def plot_transformed_images(image_paths, transform, n=3, seed=42):\n",
        "    \"\"\"Plots a series of random images from image_paths.\n",
        "\n",
        "    Will open n image paths from image_paths, transform them\n",
        "    with transform and plot them side by side.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): List of target image paths.\n",
        "        transform (PyTorch Transforms): Transforms to apply to images.\n",
        "        n (int, optional): Number of images to plot. Defaults to 3.\n",
        "        seed (int, optional): Random seed for the random generator. Defaults to 42.\n",
        "    \"\"\"\n",
        "    train_dir = breakhis_path / \"train\"\n",
        "    test_dir = breakhis_path / \"test\"\n",
        "    seed = 42\n",
        "    random.seed(seed)\n",
        "\n",
        "    random_train_image_paths = random.sample(train_images, k=n)\n",
        "    for image_path in random_train_image_paths:\n",
        "        with Image.open(image_path) as f:\n",
        "            fig, ax = plt.subplots(1, 2)\n",
        "            ax[0].imshow(f)\n",
        "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
        "            ax[0].axis(\"off\")\n",
        "\n",
        "            # Transform and plot image\n",
        "            # Note: permute() will change shape of image to suit matplotlib\n",
        "            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
        "            transformed_image = transform(f).permute(1, 2, 0)\n",
        "            ax[1].imshow(transformed_image)\n",
        "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
        "            ax[1].axis(\"off\")\n",
        "\n",
        "            fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n",
        "\n",
        "plot_transformed_images(train_images, transform=data_transform, n=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8zQRJ1esmcr"
      },
      "outputs": [],
      "source": [
        "# transforms all images in the testing and training datasets\n",
        "# Use ImageFolder to create dataset(s)\n",
        "from torchvision import datasets\n",
        "train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n",
        "                                  transform=data_transform, # transforms to perform on data (images)\n",
        "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
        "\n",
        "# Apply the same to the testing directory\n",
        "test_data = datasets.ImageFolder(root=test_dir,\n",
        "                                 transform=data_transform)\n",
        "\n",
        "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttSSdyhAsxw9"
      },
      "outputs": [],
      "source": [
        "# classes in each training dataset\n",
        "class_names = train_data.classes\n",
        "print(class_names)\n",
        "\n",
        "# mapping from class_name to index\n",
        "class_dict = train_data.class_to_idx\n",
        "print(class_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6ltenTNsyZX"
      },
      "outputs": [],
      "source": [
        "# classes in each testing dataset\n",
        "class_names = test_data.classes\n",
        "print(class_names)\n",
        "\n",
        "# mapping from class_name to index\n",
        "class_dict = test_data.class_to_idx\n",
        "print(class_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55hh2XRls1eT"
      },
      "outputs": [],
      "source": [
        "# Check the lengths\n",
        "len(train_images), len(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KC6qOmqs14y"
      },
      "outputs": [],
      "source": [
        "# Exploring the dataset\n",
        "img, label = train_data[0][0], train_data[0][1] # Extract the first image and respective label from the training dataset\n",
        "print(f\"Image tensor:\\n{img}\")\n",
        "print(f\"Image shape: {img.shape}\")\n",
        "print(f\"Image datatype: {img.dtype}\")\n",
        "print(f\"Image label: {label}\")\n",
        "print(f\"Label datatype: {type(label)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAW-6CZbs7LH"
      },
      "outputs": [],
      "source": [
        "# Rearrange the order of dimensions\n",
        "img_permute = img.permute(1, 2, 0)\n",
        "\n",
        "# Print out different shapes (before and after permute)\n",
        "print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Image permute shape: {img_permute.shape} -> [height, width, color_channels]\")\n",
        "\n",
        "# Plot the image\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.axis(\"off\")\n",
        "plt.title(class_names[label], fontsize=14);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta8TWdBstAga"
      },
      "outputs": [],
      "source": [
        "# Turn train and test Datasets into DataLoaders\n",
        "# A data-loader provides an efficient way to load data in batches\n",
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(dataset=train_data, # pull samples from train_data\n",
        "                              batch_size=1, # how many samples per batch?\n",
        "                              num_workers=1, # how many subprocesses to use for data loading? (higher = more)\n",
        "                              shuffle=True) # shuffle the data?\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=1,\n",
        "                             num_workers=1,\n",
        "                             shuffle=False) # don't usually need to shuffle testing data\n",
        "\n",
        "train_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27UjBf4HtXVn"
      },
      "outputs": [],
      "source": [
        "img, label = next(iter(train_dataloader)) # An iterator that allows us to manually pull the next batch of data\n",
        "\n",
        "# Batch size will now be 1, try changing the batch_size parameter above and see what happens\n",
        "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
        "print(f\"Label shape: {label.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8_SnWtntZy9"
      },
      "outputs": [],
      "source": [
        "# Importing more libraries\n",
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from typing import Tuple, Dict, List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpVc3J60uqfm"
      },
      "outputs": [],
      "source": [
        "# Instance of torchvision.datasets.ImageFolder()\n",
        "train_data.classes, train_data.class_to_idx # map class names to integer labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50TbA7vTuvU_"
      },
      "outputs": [],
      "source": [
        "# Get the class names from the target directory\n",
        "img, label = next(iter(train_dataloader)) # loads another batch of data\n",
        "class_names_found = train_data.classes\n",
        "print(img.shape)\n",
        "print(label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaaOXSckvWLA"
      },
      "outputs": [],
      "source": [
        "# Make function to find classes in target directory\n",
        "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
        "    \"\"\"Finds the class folder names in a target directory.\n",
        "\n",
        "    Assumes target directory is in standard image classification format.\n",
        "\n",
        "    Args:\n",
        "        directory (str): target directory to load classnames from.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], Dict[str, int]]: (list_of_class_names, dict(class_name: idx...))\n",
        "\n",
        "    Example:\n",
        "        find_classes(\"food_images/train\")\n",
        "        >>> ([\"class_1\", \"class_2\"], {\"class_1\": 0, ...})\n",
        "    \"\"\"\n",
        "    # 1. Get the class names by scanning the target directory\n",
        "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
        "\n",
        "    # 2. Raise an error if class names not found\n",
        "    if not classes:\n",
        "        raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
        "\n",
        "    # 3. Create a dictionary of index labels (computers prefer numerical rather than string labels)\n",
        "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
        "    return classes, class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zj-ohcNvhjr"
      },
      "outputs": [],
      "source": [
        "# Call the function\n",
        "find_classes(train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6nSkG57vjVD"
      },
      "outputs": [],
      "source": [
        "# Write a custom dataset class (inherits from torch.utils.data.Dataset)\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# 1. Subclass torch.utils.data.Dataset\n",
        "class ImageFolderCustom(Dataset):\n",
        "\n",
        "    # 2. Initialize with a targ_dir and transform (optional) parameter\n",
        "    def __init__(self, targ_dir: str, transform=None) -> None:\n",
        "\n",
        "        # 3. Create class attributes\n",
        "        # Get all image paths\n",
        "        self.paths = list(pathlib.Path(targ_dir).glob(\"*/*.png\")) # note: you'd have to update this if you've got .png's or .jpeg's\n",
        "        # Setup transforms\n",
        "        self.transform = transform\n",
        "        # Create classes and class_to_idx attributes\n",
        "        self.classes, self.class_to_idx = find_classes(targ_dir)\n",
        "\n",
        "    # 4. Make function to load images\n",
        "    def load_image(self, index: int) -> Image.Image:\n",
        "        \"Opens an image via a path and returns it.\"\n",
        "        image_path = self.paths[index]\n",
        "        return Image.open(image_path)\n",
        "\n",
        "    # 5. Overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)\n",
        "    def __len__(self) -> int:\n",
        "        \"Returns the total number of samples.\"\n",
        "        return len(self.paths)\n",
        "\n",
        "    # 6. Overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)\n",
        "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
        "        \"Returns one sample of data, data and label (X, y).\"\n",
        "        img = self.load_image(index)\n",
        "        class_name  = self.paths[index].parent.name # expects path in data_folder/class_name/image.jpeg\n",
        "        class_idx = self.class_to_idx[class_name]\n",
        "\n",
        "        # Transform if necessary\n",
        "        if self.transform:\n",
        "            return self.transform(img), class_idx # return data, label (X, y)\n",
        "        else:\n",
        "            return img, class_idx # return data, label (X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfsZBb-Bv4sG"
      },
      "outputs": [],
      "source": [
        "# Augment train data\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # resizes every image to specific dimensions\n",
        "    transforms.RandomHorizontalFlip(p=0.5), # flips image horizontally with a 50% chance\n",
        "    transforms.ToTensor() # converts PIL image into PyTorch tensor\n",
        "])\n",
        "\n",
        "# Don't augment test data, only reshape\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao63xkgrwTYo"
      },
      "outputs": [],
      "source": [
        "# Apply train and test transforms to the images in their respective directories\n",
        "\n",
        "train_dir = breakhis_path / \"train\"\n",
        "test_dir = breakhis_path / \"test\"\n",
        "\n",
        "train_data_custom = ImageFolderCustom(targ_dir=train_dir,\n",
        "                                      transform=train_transforms)\n",
        "test_data_custom = ImageFolderCustom(targ_dir=test_dir,\n",
        "                                     transform=test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhkfMQBYwgSb"
      },
      "outputs": [],
      "source": [
        "# Size of the datasets\n",
        "len(train_data_custom), len(test_data_custom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKRTtIBfwS7i"
      },
      "outputs": [],
      "source": [
        "# Check classes\n",
        "train_data_custom.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbIoNeb5wTDT"
      },
      "outputs": [],
      "source": [
        "# Convert to integer representation\n",
        "train_data_custom.class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vAa_KPfwTLP"
      },
      "outputs": [],
      "source": [
        "# Check for equality amongst our custom Dataset and ImageFolder Dataset\n",
        "# Checking if number of samples are equal after transforms\n",
        "print((len(train_data_custom) == len(train_data)) & (len(test_data_custom) == len(test_data)))\n",
        "print(train_data_custom.classes == train_data.classes)\n",
        "print(train_data_custom.class_to_idx == train_data.class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6Bc44gkwqOu"
      },
      "outputs": [],
      "source": [
        "# 1. Take in a Dataset as well as a list of class names\n",
        "def display_random_images(dataset: torch.utils.data.dataset.Dataset,\n",
        "                          classes: List[str] = None,\n",
        "                          n: int = 10,\n",
        "                          display_shape: bool = True,\n",
        "                          seed: int = None):\n",
        "\n",
        "    # 2. Adjust display if n too high\n",
        "    if n > 10:\n",
        "        n = 10\n",
        "        display_shape = False\n",
        "        print(f\"For display purposes, n shouldn't be larger than 10, setting to 10 and removing shape display.\")\n",
        "\n",
        "    # 3. Set random seed\n",
        "    if seed:\n",
        "        random.seed(seed)\n",
        "\n",
        "    # 4. Get random sample indexes\n",
        "    random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
        "\n",
        "    # 5. Setup plot\n",
        "    plt.figure(figsize=(16, 8))\n",
        "\n",
        "    # 6. Loop through samples and display random samples\n",
        "    for i, targ_sample in enumerate(random_samples_idx):\n",
        "        targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
        "\n",
        "        # 7. Adjust image tensor shape for plotting: [color_channels, height, width] -> [color_channels, height, width]\n",
        "        targ_image_adjust = targ_image.permute(1, 2, 0)\n",
        "\n",
        "        # Plot adjusted samples\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(targ_image_adjust)\n",
        "        plt.axis(\"off\")\n",
        "        if classes:\n",
        "            title = f\"class: {classes[targ_label]}\"\n",
        "            if display_shape:\n",
        "                title = title + f\"\\nshape: {targ_image_adjust.shape}\"\n",
        "        plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7y8v_OuVw5pn"
      },
      "outputs": [],
      "source": [
        "# Display random images from ImageFolder created Dataset\n",
        "display_random_images(train_data,\n",
        "                      n=5,\n",
        "                      classes=class_names,\n",
        "                      seed=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOLN0kCUw3bS"
      },
      "outputs": [],
      "source": [
        "# Display random images from ImageFolderCustom Dataset\n",
        "display_random_images(train_data_custom,\n",
        "                      n=12,\n",
        "                      classes=class_names,\n",
        "                      seed=None) # Try setting the seed for reproducible images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPAxWal0w5c3"
      },
      "outputs": [],
      "source": [
        "# Turn train and test custom Dataset's into DataLoader's\n",
        "from torch.utils.data import DataLoader\n",
        "train_dataloader_custom = DataLoader(dataset=train_data_custom, # use custom created train Dataset\n",
        "                                     batch_size=1, # how many samples per batch?\n",
        "                                     num_workers=0, # how many subprocesses to use for data loading? (higher = more)\n",
        "                                     shuffle=True) # shuffle the data?\n",
        "\n",
        "test_dataloader_custom = DataLoader(dataset=test_data_custom, # use custom created test Dataset\n",
        "                                    batch_size=1,\n",
        "                                    num_workers=0,\n",
        "                                    shuffle=False) # don't usually need to shuffle testing data\n",
        "\n",
        "train_dataloader_custom, test_dataloader_custom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3o34THtw3eJ"
      },
      "outputs": [],
      "source": [
        "# Get image and label from custom DataLoader\n",
        "img_custom, label_custom = next(iter(train_dataloader_custom))\n",
        "\n",
        "# Batch size will now be 1, try changing the batch_size parameter above and see what happens\n",
        "print(f\"Image shape: {img_custom.shape} -> [batch_size, color_channels, height, width]\")\n",
        "print(f\"Label shape: {label_custom.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMTTZKnKw3kt"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Create sequence of image transformations to apply to training images\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31), # how intense\n",
        "    transforms.ToTensor() # use ToTensor() last to get everything between 0 & 1\n",
        "])\n",
        "\n",
        "# Don't need to perform augmentation on the test data\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tYc5JWEx67N"
      },
      "outputs": [],
      "source": [
        "# Get all image paths\n",
        "image_path_list = list(breakhis_path.glob(\"*/*/*.png\"))\n",
        "\n",
        "# Plot random images\n",
        "plot_transformed_images(\n",
        "    image_paths=image_path_list,\n",
        "    transform=train_transforms,\n",
        "    n=3,\n",
        "    seed=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQqOdlAbyMSs"
      },
      "outputs": [],
      "source": [
        "# Create simple transform\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AB8FNFxMyN4k"
      },
      "outputs": [],
      "source": [
        "# 1. Load and transform data - using only simple transforms\n",
        "from torchvision import datasets\n",
        "train_data_simple = datasets.ImageFolder(root=train_dir, transform=simple_transform)\n",
        "test_data_simple = datasets.ImageFolder(root=test_dir, transform=simple_transform)\n",
        "\n",
        "# 2. Turn data into DataLoaders\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup batch size and number of workers\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "print(f\"Creating DataLoader's with batch size {BATCH_SIZE} and {NUM_WORKERS} workers.\")\n",
        "\n",
        "# Create DataLoader's\n",
        "train_dataloader_simple = DataLoader(train_data_simple,\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     shuffle=True,\n",
        "                                     num_workers=NUM_WORKERS)\n",
        "\n",
        "test_dataloader_simple = DataLoader(test_data_simple,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=NUM_WORKERS)\n",
        "\n",
        "train_dataloader_simple, test_dataloader_simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QXbnfKvG-cd"
      },
      "outputs": [],
      "source": [
        "# ACTUAL CNN - CLASSIFICATION MODEL\n",
        "\n",
        "# This is a hybrid CNN\n",
        "# The feature extrator is layers from the pretrained ResNet18 model CNN\n",
        "# The final classification layer (classifier head) is a standard CNN from scratch\n",
        "class HybridTinyVGGResNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Model architecture copying TinyVGG from:\n",
        "    https://poloclub.github.io/cnn-explainer/\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
        "        super().__init__() # calls the parent constructor (nn.Module) --> this is the base class for all neural network models in PyTorch\n",
        "        self.device = device # assumes device was defined earlier\n",
        "        resnet18 = models.resnet18(pretrained=True) # loads a pretrained ResNet-18 model with ImageNet weights\n",
        "        for param in resnet18.parameters():\n",
        "          param.requires_grad = False # Freeze all ResNet parameters so that they're not updated during training\n",
        "        # removes the final, fully connected classification layer from ResNet\n",
        "        # convolutional layers --> feature extractor is left\n",
        "        self.feature_extractor = nn.Sequential(*list(resnet18.children())[:-1]) # take everything except the final FC (fully connected) layer\n",
        "\n",
        "        # pass in a dummy tensor with the transformed dimensions of an image\n",
        "        # this gets the output shape of the feature extractor\n",
        "        with torch.no_grad(): # stop gradient calculations to improve efficiency in the background (and improve speed)\n",
        "          dummy_input = torch.zeros(1, input_shape, 224, 224)\n",
        "          dummy_output = self.feature_extractor(dummy_input)\n",
        "          flattened_size = dummy_output.view(1, -1).shape[1]\n",
        "\n",
        "        # stack layers in order\n",
        "        self.classifier = nn.Sequential(\n",
        "             nn.Flatten(), # flattens the feature size\n",
        "             nn.Linear(flattened_size, hidden_units),\n",
        "             nn.ReLU(), # adds non-linearity\n",
        "             nn.Linear(hidden_units, output_shape) # final layer that maps the hidden layer to the number of output classes\n",
        "        )\n",
        "\n",
        "    # Define how the data moves through the layers\n",
        "    # i.e., convolutional layers first (features extracted), and then classification\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.feature_extractor(x) # output shape -->\n",
        "        #print(x.shape)\n",
        "        x = self.classifier(x)\n",
        "        # print(x.shape)\n",
        "        return x\n",
        "        # return self.classifier(self.conv_block_2(self.conv_block_1(x))) # <- leverage the benefits of operator fusion\n",
        "\n",
        "torch.manual_seed(42) # random seed for reproducibility\n",
        "model_0 = HybridTinyVGGResNet(input_shape=3, # number of color channels (3 for RGB)\n",
        "                  hidden_units=10, # number of neurons in the hidden layer of the classifier\n",
        "                  output_shape=len(train_data.classes)).to(device) # number of output classes (2 in this case)\n",
        "\n",
        "model_0 # this displays the model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj0ZggzWyWve"
      },
      "outputs": [],
      "source": [
        "# 1. Get a batch of images and labels from the DataLoader\n",
        "img_batch, label_batch = next(iter(train_dataloader_simple))\n",
        "\n",
        "# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n",
        "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
        "print(f\"Single image shape: {img_single.shape}\\n\")\n",
        "\n",
        "# 3. Perform a forward pass on a single image\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "    pred = model_0(img_single.to(device))\n",
        "\n",
        "# 4. Print out what's happening and convert model logits -> pred probs -> pred label\n",
        "print(f\"Output logits:\\n{pred}\\n\")\n",
        "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
        "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
        "print(f\"Actual label:\\n{label_single}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ9wG4sKyb2H"
      },
      "outputs": [],
      "source": [
        "# Install torchinfo if it's not available, import it if it is\n",
        "try:\n",
        "    import torchinfo\n",
        "except:\n",
        "    !pip install torchinfo\n",
        "    import torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "summary(model_0, input_size=[1, 3, 224, 224]) # do a test pass through of an example input size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSxCapfuyfEI"
      },
      "outputs": [],
      "source": [
        "# This function takes:\n",
        "# a neural network (model), a dataloader providing batches of training data\n",
        "# a loss function to measure error\n",
        "# an optimiser to update model parameters\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer):\n",
        "    # Put model in train mode\n",
        "    model.train()\n",
        "\n",
        "    # Setup train loss and train accuracy values\n",
        "    # Initialises accumulators to keep track for the epoch\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # Loop through data loader data batches\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Send data to target device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate  and accumulate loss --> stored in a loss function\n",
        "        # Quantifies how far the predictions are from the actual values\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        # gradients accumulate by default in PyTorch, so we need to reset them before computing new gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        # Computes gradients of the loss via backpropagation\n",
        "        # Tells the optimizer how to update the parameters to reduce loss\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        # updates model parameters using calculated gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate and accumulate accuracy metrics across all batches\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "    return train_loss, train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7Cj2AkN8aFR"
      },
      "outputs": [],
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module):\n",
        "    # Put model in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Setup test loss and test accuracy values\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    # Turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "        # Loop through DataLoader batches\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            # Send data to target device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "            # 2. Calculate and accumulate loss\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Calculate and accumulate accuracy\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "    return test_loss, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m56JVoivziJh"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "# This defines a full training loop that runs through multiple epochs\n",
        "\n",
        "# 1. Take in various parameters required for training and test steps\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
        "          epochs: int = 5):\n",
        "\n",
        "    # 2. Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # 3. Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                           dataloader=train_dataloader,\n",
        "                                           loss_fn=loss_fn,\n",
        "                                           optimizer=optimizer)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "            dataloader=test_dataloader,\n",
        "            loss_fn=loss_fn)\n",
        "\n",
        "        # 4. Print out what's happening\n",
        "        print(\n",
        "            f\"Epoch: {epoch+1} | \"\n",
        "            f\"train_loss: {train_loss:.4f} | \"\n",
        "            f\"train_acc: {train_acc:.4f} | \"\n",
        "            f\"test_loss: {test_loss:.4f} | \"\n",
        "            f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # 5. Update results dictionary\n",
        "        # Ensure all data is moved to CPU and converted to float for storage\n",
        "        results[\"train_loss\"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)\n",
        "        results[\"train_acc\"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)\n",
        "        results[\"test_loss\"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
        "        results[\"test_acc\"].append(test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc)\n",
        "\n",
        "    # 6. Return the filled results at the end of the epochs\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp4YGl70z07a"
      },
      "outputs": [],
      "source": [
        "# Actually perform the training loop\n",
        "# Model is only trained on images from simple transforms (mainly only resizing)\n",
        "\n",
        "# Set random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Set number of epochs\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Recreate an instance of TinyVGG\n",
        "model_0 = HybridTinyVGGResNet(input_shape=3, # number of color channels (3 for RGB)\n",
        "                  hidden_units=10,\n",
        "                  output_shape=len(train_data.classes)).to(device)\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Train model_0\n",
        "model_0_results = train(model=model_0,\n",
        "                        train_dataloader=train_dataloader_simple,\n",
        "                        test_dataloader=test_dataloader_simple,\n",
        "                        optimizer=optimizer,\n",
        "                        loss_fn=loss_fn,\n",
        "                        epochs=NUM_EPOCHS)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mgsNihYz9NZ"
      },
      "outputs": [],
      "source": [
        "# Check the model_0_results keys\n",
        "model_0_results.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KBBtUQE0MOb"
      },
      "outputs": [],
      "source": [
        "# Function plots the statistics from the training loop\n",
        "def plot_loss_curves(results: Dict[str, List[float]]):\n",
        "    \"\"\"Plots training curves of a results dictionary.\n",
        "\n",
        "    Args:\n",
        "        results (dict): dictionary containing list of values, e.g.\n",
        "            {\"train_loss\": [...],\n",
        "             \"train_acc\": [...],\n",
        "             \"test_loss\": [...],\n",
        "             \"test_acc\": [...]}\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the loss values of the results dictionary (training and test)\n",
        "    loss = results['train_loss']\n",
        "    test_loss = results['test_loss']\n",
        "\n",
        "    # Get the accuracy values of the results dictionary (training and test)\n",
        "    accuracy = results['train_acc']\n",
        "    test_accuracy = results['test_acc']\n",
        "\n",
        "    # Figure out how many epochs there were\n",
        "    epochs = range(len(results['train_loss']))\n",
        "\n",
        "    # Setup a plot\n",
        "    plt.figure(figsize=(15, 7))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss, label='train_loss')\n",
        "    plt.plot(epochs, test_loss, label='test_loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracy, label='train_accuracy')\n",
        "    plt.plot(epochs, test_accuracy, label='test_accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5ujG1iS0VZf"
      },
      "outputs": [],
      "source": [
        "# Call the function - and see the statistics\n",
        "plot_loss_curves(model_0_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-RypFC60cJE"
      },
      "outputs": [],
      "source": [
        "# Create training transform with TrivialAugment\n",
        "# This now uses a data augmentation technique - not just resizing\n",
        "train_transform_trivial_augment = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Create testing transform (no data augmentation)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_hhZKcI1ELB"
      },
      "outputs": [],
      "source": [
        "# Turn image folders into Datasets\n",
        "train_data_augmented = datasets.ImageFolder(train_dir, transform=train_transform_trivial_augment)\n",
        "test_data_simple = datasets.ImageFolder(test_dir, transform=test_transform)\n",
        "\n",
        "train_data_augmented, test_data_simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjpnsVIP1JwK"
      },
      "outputs": [],
      "source": [
        "# Turn Datasets into DataLoaders - like done for the previous model\n",
        "import os\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_dataloader_augmented = DataLoader(train_data_augmented,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                        num_workers=NUM_WORKERS)\n",
        "\n",
        "test_dataloader_simple = DataLoader(test_data_simple,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=NUM_WORKERS)\n",
        "\n",
        "train_dataloader_augmented, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9aw6uAX04ff"
      },
      "outputs": [],
      "source": [
        "# This model, unlike the one before, will see different variations of the same training iamges each epoch\n",
        "# This may help it generalise better\n",
        "# Create model_1 and send it to the target device\n",
        "torch.manual_seed(42)\n",
        "model_1 = HybridTinyVGGResNet(\n",
        "    input_shape=3,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(train_data_augmented.classes)).to(device)\n",
        "model_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDCf9HzZ1V5y"
      },
      "outputs": [],
      "source": [
        "# Run a full training loop\n",
        "# This time, the model uses AUGMENTED data\n",
        "\n",
        "# Set random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Set number of epochs\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_1.parameters(), lr=0.001)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Train model_1\n",
        "model_1_results = train(model=model_1,\n",
        "                        train_dataloader=train_dataloader_augmented,\n",
        "                        test_dataloader=test_dataloader_simple,\n",
        "                        optimizer=optimizer,\n",
        "                        loss_fn=loss_fn,\n",
        "                        epochs=NUM_EPOCHS)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeudV73_1aUW"
      },
      "outputs": [],
      "source": [
        "# Plot statistics from this training loop\n",
        "plot_loss_curves(model_1_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0V-hpDxe1gXO"
      },
      "outputs": [],
      "source": [
        "# Summary of results\n",
        "import pandas as pd\n",
        "model_0_df = pd.DataFrame(model_0_results)\n",
        "model_1_df = pd.DataFrame(model_1_results)\n",
        "model_0_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZR-JuDo1ha7"
      },
      "outputs": [],
      "source": [
        "# Plot comparison of Model 0 and Model 1 --> simple vs. unaugmented data\n",
        "# To see which had better performance\n",
        "\n",
        "# Setup a plot\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(model_0_df))\n",
        "\n",
        "# Plot train loss\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs, model_0_df[\"train_loss\"], label=\"Model 0\")\n",
        "plt.plot(epochs, model_1_df[\"train_loss\"], label=\"Model 1\")\n",
        "plt.title(\"Train Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot test loss\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs, model_0_df[\"test_loss\"], label=\"Model 0\")\n",
        "plt.plot(epochs, model_1_df[\"test_loss\"], label=\"Model 1\")\n",
        "plt.title(\"Test Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot train accuracy\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(epochs, model_0_df[\"train_acc\"], label=\"Model 0\")\n",
        "plt.plot(epochs, model_1_df[\"train_acc\"], label=\"Model 1\")\n",
        "plt.title(\"Train Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot test accuracy\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(epochs, model_0_df[\"test_acc\"], label=\"Model 0\")\n",
        "plt.plot(epochs, model_1_df[\"test_acc\"], label=\"Model 1\")\n",
        "plt.title(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1Jeap871ss6"
      },
      "outputs": [],
      "source": [
        "# Pick a random image from the testing dataset\n",
        "random_img = random.choice(test_images)\n",
        "print(random_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOSyg1dj1xc7"
      },
      "outputs": [],
      "source": [
        "# Converts the random image into a tensor\n",
        "import torchvision\n",
        "\n",
        "# Read in custom image\n",
        "custom_image_uint8 = torchvision.io.read_image(str(random_img))\n",
        "\n",
        "# Print out image data\n",
        "print(f\"Custom image tensor:\\n{custom_image_uint8}\\n\")\n",
        "print(f\"Custom image shape: {custom_image_uint8.shape}\\n\")\n",
        "print(f\"Custom image dtype: {custom_image_uint8.dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bePCx191_7R"
      },
      "outputs": [],
      "source": [
        "# Load in custom image and convert the tensor values to float32\n",
        "custom_image = torchvision.io.read_image(str(random_img)).type(torch.float32)\n",
        "\n",
        "# Divide the image pixel values by 255 to get them between [0, 1]\n",
        "custom_image = custom_image / 255.\n",
        "\n",
        "# Print out image data\n",
        "print(f\"Custom image tensor:\\n{custom_image}\\n\")\n",
        "print(f\"Custom image shape: {custom_image.shape}\\n\")\n",
        "print(f\"Custom image dtype: {custom_image.dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uZP8lZH2C8A"
      },
      "outputs": [],
      "source": [
        "# Plot custom image\n",
        "print(\"From testing dataset:\")\n",
        "custom_image = torch.clamp(custom_image, 0, 1)\n",
        "plt.imshow(custom_image.permute(1, 2, 0)) # need to permute image dimensions from CHW -> HWC otherwise matplotlib will error\n",
        "plt.title(f\"Image shape: {custom_image.shape}\")\n",
        "plt.axis(False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZu8nNWa2GeB"
      },
      "outputs": [],
      "source": [
        "# Create transform pipeline to resize image\n",
        "custom_image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "])\n",
        "\n",
        "# Transform target image\n",
        "custom_image_transformed = custom_image_transform(custom_image)\n",
        "\n",
        "# Print out original shape and new shape\n",
        "print(f\"Original shape: {custom_image.shape}\")\n",
        "print(f\"New shape: {custom_image_transformed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWvMFJes2LTV"
      },
      "outputs": [],
      "source": [
        "model_1.eval() # Puts model into evaluation mode\n",
        "with torch.inference_mode():\n",
        "    # Add an extra dimension to image\n",
        "    custom_image_transformed_with_batch_size = custom_image_transformed.unsqueeze(dim=0)\n",
        "\n",
        "    # Print out different shapes\n",
        "    print(f\"Custom image transformed shape: {custom_image_transformed.shape}\")\n",
        "    print(f\"Unsqueezed custom image shape: {custom_image_transformed_with_batch_size.shape}\")\n",
        "\n",
        "    # Make a prediction on image with an extra dimension\n",
        "    custom_image_pred = model_1(custom_image_transformed.unsqueeze(dim=0).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ67Fw5z2V1T"
      },
      "outputs": [],
      "source": [
        "# Prints the prediction of the image --> for a single, transformed image\n",
        "# Will output raw scores applied to both classes, before applying softmax\n",
        "custom_image_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cItuG3K2qOE"
      },
      "outputs": [],
      "source": [
        "# Print out prediction logits\n",
        "print(f\"Prediction logits: {custom_image_pred}\")\n",
        "\n",
        "# Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)\n",
        "custom_image_pred_probs = torch.softmax(custom_image_pred, dim=1)\n",
        "print(f\"Prediction probabilities: {custom_image_pred_probs}\")\n",
        "\n",
        "# Convert prediction probabilities -> prediction labels\n",
        "custom_image_pred_label = torch.argmax(custom_image_pred_probs, dim=1)\n",
        "print(f\"Prediction label: {custom_image_pred_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O51Hnl7m2sgy"
      },
      "outputs": [],
      "source": [
        "# Find the predicted label\n",
        "custom_image_pred_class = class_names[custom_image_pred_label.cpu()] # put pred label to CPU, otherwise will error\n",
        "custom_image_pred_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnIdFH8T2ubH"
      },
      "outputs": [],
      "source": [
        "# The values of the prediction probabilities are quite similar\n",
        "custom_image_pred_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb1XnyjU2v98"
      },
      "outputs": [],
      "source": [
        "\"\"\"Makes a prediction on a target image and plots the image with its prediction.\"\"\"\n",
        "def pred_and_plot_image(model: torch.nn.Module,\n",
        "                        image_path: str,\n",
        "                        class_names: List[str] = None,\n",
        "                        transform=None,\n",
        "                        device: torch.device = device):\n",
        "\n",
        "    # 1. Load in image and convert the tensor values to float32\n",
        "    target_image = torchvision.io.read_image(str(image_path)).type(torch.float32)\n",
        "\n",
        "    # 2. Divide the image pixel values by 255 to get them between [0, 1]\n",
        "    target_image = target_image / 255.\n",
        "\n",
        "    # 3. Transform if necessary\n",
        "    if transform:\n",
        "        target_image = transform(target_image)\n",
        "\n",
        "    # 4. Make sure the model is on the target device\n",
        "    model.to(device)\n",
        "\n",
        "    # 5. Turn on model evaluation mode and inference mode\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        # Add an extra dimension to the image\n",
        "        target_image = target_image.unsqueeze(dim=0)\n",
        "\n",
        "        # Make a prediction on image with an extra dimension and send it to the target device\n",
        "        target_image_pred = model(target_image.to(device))\n",
        "\n",
        "    # 6. Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)\n",
        "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
        "\n",
        "    # 7. Convert prediction probabilities -> prediction labels\n",
        "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
        "\n",
        "    # 8. Plot the image alongside the prediction and prediction probability\n",
        "    image_to_plot = target_image.squeeze().permute(1, 2, 0).cpu().numpy() # make sure it's the right size for matplotlib\n",
        "    image_to_plot = np.clip(image_to_plot, 0, 1)\n",
        "    plt.imshow(image_to_plot)\n",
        "    if class_names:\n",
        "        title = f\"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
        "    else:\n",
        "        title = f\"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.axis(False);\n",
        "\n",
        "    # Returns the prediction of the image (the integer representation)\n",
        "    pred_label = int(target_image_pred_label.item())\n",
        "    return pred_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OK-NyEVX27bN"
      },
      "outputs": [],
      "source": [
        "# Prediction on our custom (random) image\n",
        "random_img = random.choice(test_images)\n",
        "\n",
        "pred_label = pred_and_plot_image(model=model_1,\n",
        "                    image_path=random_img,\n",
        "                    class_names=class_names,\n",
        "                    transform=custom_image_transform,\n",
        "                    device=device)\n",
        "\n",
        "true_label = random_img.parent.name\n",
        "print(f\"Prediction: {class_names[pred_label].capitalize()}\")\n",
        "print(f\"True label: {true_label.capitalize()}\")\n",
        "\n",
        "if str(class_names[pred_label]) == str(true_label):\n",
        "  print(\"Prediction is correct!\")\n",
        "else:\n",
        "  print(\"Incorrect prediction.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEPSILUS3bZwsdHo6NOVXd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}